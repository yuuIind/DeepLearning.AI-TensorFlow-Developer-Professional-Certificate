{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-1-public/blob/main/C1/W2/ungraded_labs/C1_W2_Lab_2_callbacks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBNo9JrZIYG6"
   },
   "source": [
    "# Ungraded Lab: Using Callbacks to Control Training\n",
    "\n",
    "In this lab, you will use the [Callbacks API](https://keras.io/api/callbacks/) to stop training when a specified metric is met. This is a useful feature so you won't need to complete all epochs when this threshold is reached. For example, if you set 1000 epochs and your desired accuracy is already reached at epoch 200, then the training will automatically stop. Let's see how this is implemented in the next sections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mcwrn9AKKVb8"
   },
   "source": [
    "## Load and Normalize the Fashion MNIST dataset\n",
    "\n",
    "Like the previous lab, you will use the Fashion MNIST dataset again for this exercise. And also as mentioned before, you will normalize the pixel values to help optimize the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "8LTaefqDJMIn"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Instantiate the dataset API\n",
    "fmnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "# Load the dataset\n",
    "(x_train, y_train),(x_test, y_test) = fmnist.load_data()\n",
    "\n",
    "# Normalize the pixel values\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ia2OadhALJjS"
   },
   "source": [
    "## Creating a Callback class\n",
    "\n",
    "You can create a callback by defining a class that inherits the [tf.keras.callbacks.Callback](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback) base class. From there, you can define available methods to set where the callback will be executed. For instance below, you will use the [on_epoch_end()](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback#on_epoch_end) method to check the loss at each training epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "uuRmQZWVJAJH"
   },
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    '''\n",
    "    Halts the training after reaching 60 percent accuracy\n",
    "\n",
    "    Args:\n",
    "      epoch (integer) - index of epoch (required but unused in the function definition below)\n",
    "      logs (dict) - metric results from the training epoch\n",
    "    '''\n",
    "\n",
    "    # Check accuracy\n",
    "    if(logs.get('accuracy') >= 0.95):\n",
    "\n",
    "      # Stop if threshold is met\n",
    "      print(\"\\nLoss is lower than 0.4 so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "# Instantiate class\n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xlXeLkFeMn8"
   },
   "source": [
    "## Define and compile the model\n",
    "\n",
    "Next, you will define and compile the model. The architecture will be similar to the one you built in the previous lab. Afterwards, you will set the optimizer, loss, and metrics that you will use for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "7JXxMg3TpzER"
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.optimizers.Adam(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6eLe4cPZe-ui"
   },
   "source": [
    "### Train the model\n",
    "\n",
    "Now you are ready to train the model. To set the callback, simply set the `callbacks` parameter to the `myCallback` instance you declared before. Run the cell below and observe what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nLXTB32de3_e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.4917 - accuracy: 0.8213\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.3692 - accuracy: 0.8650\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.3340 - accuracy: 0.8774\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.3103 - accuracy: 0.8847\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2905 - accuracy: 0.8912\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2766 - accuracy: 0.8957\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2644 - accuracy: 0.9019\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2516 - accuracy: 0.9053\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2447 - accuracy: 0.9082\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2330 - accuracy: 0.9117\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.2237 - accuracy: 0.9153\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2176 - accuracy: 0.9173\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2101 - accuracy: 0.9202\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.2034 - accuracy: 0.9229\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.1973 - accuracy: 0.9255\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.1902 - accuracy: 0.9277\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.1872 - accuracy: 0.9294\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.1819 - accuracy: 0.9308\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.1781 - accuracy: 0.9318\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1728 - accuracy: 0.9335\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1685 - accuracy: 0.9359\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.1626 - accuracy: 0.9381\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1595 - accuracy: 0.9389\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.1570 - accuracy: 0.9395\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1522 - accuracy: 0.9420\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.1516 - accuracy: 0.9421\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1489 - accuracy: 0.9436\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1449 - accuracy: 0.9452\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1394 - accuracy: 0.9465\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1359 - accuracy: 0.9488\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.1326 - accuracy: 0.9493\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.1306 - accuracy: 0.9495\n",
      "Epoch 33/50\n",
      "1873/1875 [============================>.] - ETA: 0s - loss: 0.1339 - accuracy: 0.9501\n",
      "Loss is lower than 0.4 so cancelling training!\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1341 - accuracy: 0.9501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e71701af90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with a callback\n",
    "model.fit(x_train, y_train, epochs=50, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGBSkRQPff93"
   },
   "source": [
    "You will notice that the training does not need to complete all 10 epochs. By having a callback at each end of the epoch, it is able to check the training parameters and compare if it meets the threshold you set in the function definition. In this case, it will simply stop when the loss falls below `0.40` after the current epoch.\n",
    "\n",
    "*Optional Challenge: Modify the code to make the training stop when the accuracy metric exceeds 60%.*\n",
    "\n",
    "That concludes this simple exercise on callbacks!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "C1_W2_Lab_2_callbacks.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "https://github.com/https-deeplearning-ai/tensorflow-1-public/blob/adding_C1/C1/W2/ungraded_labs/C1_W2_Lab_2_callbacks.ipynb",
     "timestamp": 1638884482962
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
